---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```
# LRTesteR Overview
<!-- badges: start -->
[![R build status](https://github.com/gmcmacran/LRTesteR/workflows/R-CMD-check/badge.svg)](https://github.com/gmcmacran/LRTesteR/actions)
[![CRAN status](https://www.r-pkg.org/badges/version/LRTesteR)](https://cran.r-project.org/package=LRTesteR)
<!-- badges: end -->

LRTesteR provides likelihood ratio test and associated confidence intervals for many common distributions. All tests and CIs rely on the $$\chi^2$$ approximation even when exact sampling distributions are known. Tests require a sample size of at least 50. Estimated asymptotic type I and type II error rates can be found [here](https://github.com/gmcmacran/TypeOneTypeTwoSim).

All functions match popular tests in R. If you are familiar with t.test and binom.test, you already know how to use these functions.

# Implemented Tests and Confidence Intervals

* beta
  + shape 1
  + shape 2

* binomial
  + p
  
* exponential
  + rate
  
* gamma
  + rate
  + scale
  + shape
  
* Gaussian
  + mu
  + variance
  
* negative binomial
  + p
  
* Poisson
  + lambda

* Cauchy
  + location
  + scale

# Example 1: Test lambda of a poisson distribution

Lets create some data to work with.

```{r example1Part1}
library(LRTesteR)

set.seed(1)
x <- rpois(n = 100, lambda = 1)
```

To test lambda, simply call poisson_lambda_lr_test.
```{r example1Part2}
poisson_lambda_lr_test(x = x, lambda = 1, alternative = "two.sided")
```
Because we generated the data, we know the true value of lambda is one. The p value is above 5%.

# Example 2: Confidence Interval

To get a confidence interval, set the conf.level to the desired confidence. Below gets a two sided 90% confidence interval for scale from a Cauchy random variable.

```{r example2Part1}
set.seed(1)
x <- rcauchy(n = 100, location = 3, scale = 5)
cauchy_scale_lr_test(x = x, scale = 1, alternative = "two.sided", conf.level = .90)
```

Setting alternative to "less" gets a lower one sided interval. Setting it to "greater" gets an upper one sided interval.

# Mathematical Details

The strength of the likelihood ratio test is its generality. It is a recipe to create hypothesis tests and confidence intervals in many different settings. Sometimes the test is the only known procedure. When there are many procedures, likelihood ratio tests have very competitive **asymptotic** power.

The weakness of the likelihood ratio test is it depends on two assumptions:

* N is sufficiently large.
* Parameters are in the interior of the parameter space.

For the first condition, type I error rates and confidence interval coverage rates improve as N increases. For a given N, type I error rates are **close** to alpha and coverage rates are **close** to the confidence level. This is the reason all tests require a sample size of at least 50. For the second condition, the parameter must not be near the boundary of the parameter space. How near is too near depends on N.

As implemented, all functions depend on the $$\chi^2$$ approximation. To get a sense of performance, lets compare the likelihood method to the exact method. Here, X is normally distributed with mu equal to 3 and standard deviation equal to 2.

```{r MDPart1}
set.seed(1)
x <- rnorm(n = 50, mean = 3, sd = 2)
exactTest <- t.test(x = x, mu = 2.5, alternative = "two.sided", conf.level = .95)
likelihoodTest <- gaussian_mu_lr_test(x = x, mu = 2.5, alternative = "two.sided", conf.level = .95)
```

The two intervals are similar.
```{r MDPart2}
as.numeric(exactTest$conf.int)
likelihoodTest$conf.int
```

Lets compare tests for variance. Again, confidence intervals are similar.
```{r MDPart3}
sigma2 <- 1.5^2 # Variance, not standard deviation.
exactTest <- EnvStats::varTest(x = x, sigma.squared = sigma2,  alternative = "two.sided", conf.level = .95)
likelihoodTest <- gaussian_variance_lr_test(x = x, sigma.squared = sigma2, alternative = "two.sided", conf.level = .95)
as.numeric(exactTest$conf.int)
likelihoodTest$conf.int
```

Changing to p for a binomial distribution, the confidence intervals are similar yet again. 
```{r MDPart4}
sigma2 <- 1.5^2 # Variance, not standard deviation.
exactTest <- stats::binom.test(x = 10, n = 50,  p = .50, alternative = "two.sided", conf.level = .95)
likelihoodTest <- binomial_p_lr_test(x = 10, n = 50,  p = .50, alternative = "two.sided", conf.level = .95)
as.numeric(exactTest$conf.int)
likelihoodTest$conf.int
```

When exact methods are known, use them. The utility of the likelihood based approach is its generality. Many tests in this package (cauchy, beta, gamma, poisson) don't have other well known options.

Asymptotic type I and type II error rates can be found [here](https://github.com/gmcmacran/TypeOneTypeTwoSim).
